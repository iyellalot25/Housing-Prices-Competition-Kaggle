# ğŸ  House Price Prediction | Kaggle ML Competition

A machine learning project built for the Kaggle **House Prices: Advanced Regression Techniques** competition. This project uses a **Random Forest Regressor** to predict house sale prices from structured housing data, following a complete end-to-end machine learning workflow.

The focus is on feature selection, model training, validation using **Mean Absolute Error (MAE)**, and generating Kaggle-ready submission files.

---

## âœ¨ Features

* Structured data loading and preprocessing using Pandas
* Feature selection based on housing attributes
* Train-validation split for model evaluation
* Random Forest regression model
* Model performance evaluation using MAE
* Generation of competition submission file

---

## ğŸ›  Tech Stack

* **Python**
* **Pandas** â€“ Data manipulation
* **scikit-learn** â€“ Model training & evaluation
* **Random Forest Regressor** â€“ Prediction model

---

## ğŸ“‚ Dataset

* **Competition:** House Prices â€“ Advanced Regression Techniques
* **Source:** Kaggle
* **Files Used:**

  * `train.csv` â€“ Training data
  * `test.csv` â€“ Test data

---

## ğŸš€ How to Run Locally

1. Clone the repository

   ```bash
   git clone <repo-url>
   ```
2. Install dependencies

   ```bash
   pip install pandas scikit-learn
   ```
3. Place `train.csv` and `test.csv` in the project directory
4. Run the script

   ```bash
   python main.py
   ```
5. A `submission.csv` file will be generated for Kaggle upload

---

## ğŸ“Š Model Evaluation

* **Model:** Random Forest Regressor
* **Metric:** Mean Absolute Error (MAE)
* **Validation Strategy:** Train / Validation split

---

## ğŸ“Œ Project Type

> **Machine learning learning project** focused on understanding regression models, evaluation metrics, and competition-style ML workflows.

---

## ğŸš§ Future Improvements

* Feature engineering and handling missing values
* Hyperparameter tuning
* Cross-validation
* Comparison with other regression models (XGBoost, Gradient Boosting)

---
